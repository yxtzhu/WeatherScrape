{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import libraries for webscraping\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "#Import libraries for data manipulation and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#import datetime\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Government of Canada Website\n",
    "#let's scrape 5 year worth of data. That is from Jan 2017\n",
    "pagelist=[]\n",
    "now = datetime.now()\n",
    "\n",
    "for year in range(2008, 2019):\n",
    "    for month in range(1, 13):\n",
    "        if now.year > year or (now.year==year and month<=now.month):\n",
    "            url='http://climate.weather.gc.ca/climate_data/daily_data_e.html?StationID=51459&timeframe=2&StartYear=1840&EndYear=2018&Day=7&Year='+str(year)+'&Month='+str(month)+'#'\n",
    "            pagelist.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ScrapeWeather(page):\n",
    "    #Query the website\n",
    "    f=urllib.request.urlopen(page).read()\n",
    "    \n",
    "    #Parse the page using beautiful soup\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "    \n",
    "    #Find the section that contains the year and the month\n",
    "    option = soup.find_all('div', class_='col-md-6 col-sm-6 col-xs-6 text-center mrgn-tp-md mrgn-bttm-md')\n",
    "    option=option[0]\n",
    "    option=option.find_all('option', selected=True)\n",
    "    \n",
    "    #Find the table\n",
    "    table = soup.find_all('table')\n",
    "    \n",
    "    #Find title\n",
    "    th_all = soup.find_all('th')\n",
    "    result = []\n",
    "    for th in th_all:\n",
    "        result.append(th.find('abbr', text=True))\n",
    "\n",
    "    title=[]\n",
    "    for abbr in result:\n",
    "        if abbr is not None:\n",
    "            title.append(abbr.string)\n",
    "            \n",
    "    #clean up title\n",
    "    for i in range(len(title)):\n",
    "        if title[i]=='mm':\n",
    "            title[i]=\"Total Rain\"\n",
    "        elif title[i]=='cm':\n",
    "            title[i]=\"Total Snow\"\n",
    "    \n",
    "    #Find data\n",
    "    table_body = soup.find('tbody')\n",
    "    tr = table_body.find_all('tr')\n",
    "    td=[]\n",
    "    date=[]\n",
    "    data=[]\n",
    "    for row in tr:\n",
    "        d=[]\n",
    "        for r in row.find_all('td'):\n",
    "            date.append(r.find('abbr'))\n",
    "            d.append(r.string)\n",
    "        data.append(d)\n",
    "    \n",
    "    #clean date arrays\n",
    "    t=[]\n",
    "    for d in date:\n",
    "        if d is not None:\n",
    "            t.append(d.get('title'))\n",
    "    \n",
    "    date=[]\n",
    "    for j in t:\n",
    "        date.append(datetime.strptime(j, '%B %d, %Y'))\n",
    "\n",
    "    #clean up data array\n",
    "    for entry in data:\n",
    "        if entry == []:\n",
    "            data.remove(entry)\n",
    "\n",
    "    for entry in data:\n",
    "        if len(entry)>11:\n",
    "            entry.pop(0)\n",
    "\n",
    "    #There should be as many rows as the number dates\n",
    "    for rm in range(len(data)-len(date)):\n",
    "        data.pop(len(data)-1)\n",
    "        rm -=1\n",
    "    \n",
    "    for rm in range(len(title)-len(data[0])):\n",
    "        title.pop(len(title)-1)\n",
    "        rm-=1\n",
    "    \n",
    "    #Construct dataframe for scraped data\n",
    "    df = pd.DataFrame(data=data,index=date,columns=title)\n",
    "    df=df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    \n",
    "    #Aggregate average\n",
    "    Mmean=df[\"Mean Temp\"].mean()\n",
    "    Mmax=max(df['Max Temp'])\n",
    "    Mmin=min(df['Min Temp'])\n",
    "    Mindex=df.index[0]\n",
    "    \n",
    "    md={'Mean Temp': Mmean, 'Delta':Mmax-Mmin}\n",
    "    mdf=pd.DataFrame(md, index=[Mindex])\n",
    "    return(mdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Delta  Mean Temp\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "2013-06-11    NaN  17.937500\n",
      "...           ...        ...\n",
      "2015-08-01   21.7  20.716129\n",
      "2015-09-01   26.7  19.693333\n",
      "2015-10-01   26.0   9.941935\n",
      "2015-11-01   27.8   6.500000\n",
      "2015-12-01   22.1   4.138710\n",
      "2016-01-01   26.0  -3.625806\n",
      "2016-02-01   42.3  -2.289655\n",
      "2016-03-01   31.3   2.641935\n",
      "2016-04-01   34.5   4.840000\n",
      "2016-05-01   31.4  14.593548\n",
      "2016-06-01   27.2  19.983333\n",
      "2016-07-01   23.7  23.706452\n",
      "2016-08-01   22.8  24.303226\n",
      "2016-09-01   27.1  19.450000\n",
      "2016-10-01   25.7  11.867742\n",
      "2016-11-01   23.0   6.740000\n",
      "2016-12-01   23.5  -1.612903\n",
      "2017-01-01   23.1  -1.641935\n",
      "2017-02-01   29.7  -0.228571\n",
      "2017-03-01   29.7  -0.516129\n",
      "2017-04-01   26.3   9.416667\n",
      "2017-05-01   28.1  12.580645\n",
      "2017-06-01   24.8  19.337931\n",
      "2017-07-01   18.0  21.758065\n",
      "2017-08-01   20.3  20.051613\n",
      "2017-09-01   27.6  18.746667\n",
      "2017-10-01   25.8  13.216667\n",
      "2017-11-01   27.2   3.717241\n",
      "2017-12-01   34.2  -5.177419\n",
      "2018-01-01   36.1  -8.423529\n",
      "\n",
      "[121 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "frames=[]\n",
    "for page in pagelist:\n",
    "    frames.append(ScrapeWeather(page))\n",
    "\n",
    "result = pd.concat(frames)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.graph_objs import Scatter, Figure, Layout\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~yxtzhu/12.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace1 = go.Bar(\n",
    "    x=result.index,\n",
    "    y=result['Delta'],\n",
    "    name='Delta',\n",
    "    marker=dict(\n",
    "        color='rgb(158,202,225)',\n",
    "        line=dict(\n",
    "            color='rgb(8,48,107)',\n",
    "            width=1.5,\n",
    "        )\n",
    "    ),\n",
    "    opacity=0.6\n",
    ")\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    x = result.index,\n",
    "    y = result['Mean Temp'],\n",
    "    name='Mean Temp',\n",
    "    line = dict(\n",
    "        color = ('rgb(255, 175, 102)'),\n",
    "        width = 4,\n",
    "        dash = 'dot')\n",
    ")\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    title = 'Toronto Weather Data'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='MonthlyDeltaWeather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
